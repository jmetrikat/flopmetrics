{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python-dotenv could not parse statement starting at line 1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "import pandas as pd\n",
    "from flopmetrics.profiler import TorchProfiler\n",
    "from flopmetrics.ncu import NCUProfiler\n",
    "from flopmetrics.network import ToyNetwork, run_toy_network_forward_ncu, run_toy_network_forward_backward_ncu, construct_toy_network_and_input_for_ncu\n",
    "\n",
    "os.makedirs(\"results\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analytical vs PyTorch vs NCU Comparison\n",
    "Single fixed config n, d, m = 10, 1024, 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def toy_network_forward_flops(dim, n_layers, n_tokens):\n",
    "    with TorchProfiler() as prof:\n",
    "        net = ToyNetwork(n_layers=n_layers, dim=dim)\n",
    "        x = torch.randn(dim, n_tokens, device=\"cuda\")\n",
    "        with prof.record_context(\"forward\"):\n",
    "            _ = net(x)\n",
    "    return prof.get_flops_by_step().loc[\"forward\", \"flops\"]\n",
    "\n",
    "\n",
    "def toy_network_backward_flops(dim, n_layers, n_tokens):\n",
    "    with TorchProfiler() as prof:\n",
    "        net = ToyNetwork(n_layers=n_layers, dim=dim)\n",
    "        x = torch.randn(dim, n_tokens, device=\"cuda\")\n",
    "        y = net(x)\n",
    "        with prof.record_context(\"backward\"):\n",
    "            y.sum().backward()\n",
    "    return prof.get_flops_by_step().loc[\"backward\", \"flops\"]\n",
    "\n",
    "\n",
    "def toy_network_forward_flops_ncu(dim, n_layers, n_tokens):\n",
    "    ncu = NCUProfiler()\n",
    "    _ = ncu.profile_function(run_toy_network_forward_ncu, {\n",
    "        \"dim\": dim,\n",
    "        \"n_layers\": n_layers,\n",
    "        \"n_tokens\": n_tokens,\n",
    "    })\n",
    "    flops = ncu.get_total_flops()\n",
    "\n",
    "    ncu2 = NCUProfiler()\n",
    "    ncu2.profile_function(construct_toy_network_and_input_for_ncu, {\n",
    "        \"dim\": dim,\n",
    "        \"n_layers\": n_layers,\n",
    "        \"n_tokens\": n_tokens,\n",
    "    })\n",
    "    setup_flops = ncu2.get_total_flops()\n",
    "    flops -= setup_flops\n",
    "\n",
    "    ncu.result.to_csv(\"experiments/toy_network/results/toy_network_forward_flops_ncu.csv\")\n",
    "    ncu2.result.to_csv(\"experiments/toy_network/results/toy_network_setup_flops_ncu.csv\")\n",
    "\n",
    "    return flops\n",
    "\n",
    "\n",
    "def toy_network_forward_backward_flops_ncu(dim, n_layers, n_tokens):\n",
    "    ncu = NCUProfiler()\n",
    "    _ = ncu.profile_function(run_toy_network_forward_backward_ncu, {\n",
    "        \"dim\": dim,\n",
    "        \"n_layers\": n_layers,\n",
    "        \"n_tokens\": n_tokens,\n",
    "    })\n",
    "    flops = ncu.get_total_flops()\n",
    "\n",
    "    ncu.result.to_csv(\"experiments/toy_network/results/toy_network_forward_backward_flops_ncu.csv\")\n",
    "\n",
    "    ncu2 = NCUProfiler()\n",
    "    ncu2.profile_function(construct_toy_network_and_input_for_ncu, {\n",
    "        \"dim\": dim,\n",
    "        \"n_layers\": n_layers,\n",
    "        \"n_tokens\": n_tokens,\n",
    "    })\n",
    "    setup_flops = ncu2.get_total_flops()\n",
    "    flops -= setup_flops\n",
    "\n",
    "    return flops\n",
    "\n",
    "\n",
    "def toy_network_params(dim, n_layers):\n",
    "    net = ToyNetwork(n_layers=n_layers, dim=dim)\n",
    "    return sum(p.numel() for p in net.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 10      # number of layers\n",
    "D = 1024    # size of input/output dimension\n",
    "M = 128     # sequence length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10485760\n",
      "                                                 forward_flops  backward_flops\n",
      "torch profiler (experimental)                    2,684,354,560   5,100,273,664\n",
      "ncu profiler (experimental)                      2,727,606,309   5,134,953,113\n",
      "theoretical (analyzed)                           2,684,354,560   5,100,273,664\n",
      "theoretical exact (analyzed)                     2,685,665,280   5,102,764,032\n",
      "theoretical exact gpu implementation (analyzed)  2,685,665,280   5,102,764,032\n"
     ]
    }
   ],
   "source": [
    "baseline_num_params = toy_network_params(D, N)\n",
    "print(baseline_num_params)\n",
    "\n",
    "baseline_forward_flops_exp = toy_network_forward_flops(D, N, M)\n",
    "baseline_backward_flops_exp = toy_network_backward_flops(D, N, M)\n",
    "\n",
    "baseline_forward_flops_ncu = toy_network_forward_flops_ncu(D, N, M)\n",
    "baseline_backward_flops_ncu = toy_network_forward_backward_flops_ncu(D, N, M) - baseline_forward_flops_ncu\n",
    "\n",
    "baseline_forward_flops_theory = N * (2 * D * D * M)\n",
    "baseline_backward_flops_theory = (N - 1) * (4 * D * D * M) + 2 * D * D * M\n",
    "\n",
    "baseline_forward_flops_theory_exact = baseline_forward_flops_theory + N * (D * M)\n",
    "baseline_backward_flops_theory_exact = baseline_backward_flops_theory + (N - 1) * (2 * D * M) + D * M\n",
    "\n",
    "baseline_forward_flops_theory_exact_gpu = baseline_forward_flops_theory_exact # TODO: add actual equation\n",
    "baseline_backward_flops_theory_exact_gpu = baseline_backward_flops_theory_exact # TODO: add actual equation\n",
    "\n",
    "baseline_df = pd.DataFrame(\n",
    "    {\n",
    "        \"forward_flops\": [baseline_forward_flops_exp, baseline_forward_flops_ncu, baseline_forward_flops_theory, baseline_forward_flops_theory_exact, baseline_forward_flops_theory_exact_gpu],\n",
    "        \"backward_flops\": [baseline_backward_flops_exp, baseline_backward_flops_ncu, baseline_backward_flops_theory, baseline_backward_flops_theory_exact, baseline_backward_flops_theory_exact_gpu],\n",
    "    },\n",
    "    index=[\"torch profiler (experimental)\", \"ncu profiler (experimental)\", \"theoretical (analyzed)\", \"theoretical exact (analyzed)\", \"theoretical exact gpu implementation (analyzed)\"],\n",
    ")\n",
    "pd.set_option('display.float_format', '{:,.0f}'.format)\n",
    "print(baseline_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analytical vs PyTorch Comparison\n",
    "Fixed n=32, m=128, d from 128 to 2048 with step 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running PyTorch vs Analytical comparison...\n",
      "Parameters: N=32, M=128, D_values=[128, 256, 384, 512, 640, 768, 896, 1024, 1152, 1280, 1408, 1536, 1664, 1792, 1920, 2048]\n",
      "Processing D=128...\n",
      "Processing D=256...\n",
      "Processing D=384...\n",
      "Processing D=512...\n",
      "Processing D=640...\n",
      "Processing D=768...\n",
      "Processing D=896...\n",
      "Processing D=1024...\n",
      "Processing D=1152...\n",
      "Processing D=1280...\n",
      "Processing D=1408...\n",
      "Processing D=1536...\n",
      "Processing D=1664...\n",
      "Processing D=1792...\n",
      "Processing D=1920...\n",
      "Processing D=2048...\n",
      "\n",
      "Comparison completed!\n",
      "Results saved to: results/analytical_vs_pytorch_comparison.csv\n",
      "\n",
      "Summary:\n",
      "       D  forward_error_pct  backward_error_pct\n",
      "0    128               0.39                0.39\n",
      "1    256               0.19                0.19\n",
      "2    384               0.13                0.13\n",
      "3    512               0.10                0.10\n",
      "4    640               0.08                0.08\n",
      "5    768               0.07                0.07\n",
      "6    896               0.06                0.06\n",
      "7   1024               0.05                0.05\n",
      "8   1152               0.04                0.04\n",
      "9   1280               0.04                0.04\n",
      "10  1408               0.04                0.04\n",
      "11  1536               0.03                0.03\n",
      "12  1664               0.03                0.03\n",
      "13  1792               0.03                0.03\n",
      "14  1920               0.03                0.03\n",
      "15  2048               0.02                0.02\n"
     ]
    }
   ],
   "source": [
    "N = 32\n",
    "M = 128\n",
    "D_values = list(range(128, 2049, 128))\n",
    "\n",
    "results = []\n",
    "\n",
    "print(\"Running PyTorch vs Analytical comparison...\")\n",
    "print(f\"Parameters: N={N}, M={M}, D_values={D_values}\")\n",
    "\n",
    "for D in D_values:\n",
    "    print(f\"Processing D={D}...\")\n",
    "\n",
    "    pytorch_forward_flops = toy_network_forward_flops(D, N, M)\n",
    "    pytorch_backward_flops = toy_network_backward_flops(D, N, M)\n",
    "\n",
    "    analytical_forward_flops = N * (2 * D * D * M) + N * (D * M)\n",
    "    analytical_backward_flops = (N - 1) * (4 * D * D * M) + 2 * D * D * M + (N - 1) * (2 * D * M) + D * M\n",
    "\n",
    "    results.append({\n",
    "        'D': D,\n",
    "        'pytorch_forward_flops': pytorch_forward_flops,\n",
    "        'pytorch_backward_flops': pytorch_backward_flops,\n",
    "        'analytical_forward_flops': analytical_forward_flops,\n",
    "        'analytical_backward_flops': analytical_backward_flops,\n",
    "        'forward_error_pct': abs(pytorch_forward_flops - analytical_forward_flops) / analytical_forward_flops * 100,\n",
    "        'backward_error_pct': abs(pytorch_backward_flops - analytical_backward_flops) / analytical_backward_flops * 100\n",
    "    })\n",
    "\n",
    "comparison_df = pd.DataFrame(results)\n",
    "comparison_df.to_csv(\"results/analytical_vs_pytorch_comparison.csv\", index=False)\n",
    "\n",
    "print(\"\\nComparison completed!\")\n",
    "print(f\"Results saved to: results/analytical_vs_pytorch_comparison.csv\")\n",
    "print(\"\\nSummary:\")\n",
    "print(comparison_df[['D', 'forward_error_pct', 'backward_error_pct']].round(2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "flopmetrics-eiHSHlc7-py3.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
